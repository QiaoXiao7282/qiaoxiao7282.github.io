<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0026)https://qiaoxiao7282.github.io/#home -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <script type="text/javascript" async="" src="indexpics/inpage_linkid.js.download" id="undefined"></script><script type="text/javascript" async="" src="indexpics/ga.js.download"></script><script type="text/javascript" async="" src="indexpics/ga.js.download"></script><script src="indexpics/head.js.download"></script>        <meta name="author" content="Qiao Xiao">    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Qiao Xiao is a Postdoctoral Researcher at Meta AI.">
    <meta name="keywords" content="Qiao Xiao,Computer,Vision,Machine,Learning,Lipreading,Science,Homepage,Meta">
    <title>Qiao Xiao</title>

    <link rel="stylesheet" href="indexpics/main.css">
    <script src="indexpics/main.js.download"></script>
    <script src="indexpics/scroll.js.download"></script>
    <script async="" type="text/javascript" src="indexpics/google.js.download"></script>

  <script src="indexpics/google_analytics_auto.js.download"></script></head>

  <body data-new-gr-c-s-check-loaded="14.991.0" data-gr-ext-installed="">

    <div class="outercontainer">
      
      <script src="indexpics/header.js.download"></script><header>  <div class="container header">    <div class="ftheader text"><a href="index.html#home">Qiao Xiao</a></div>    <div class="ftsubheader text"><a href="index.html#publications">Publications</a></div>    <div class="ftsubheader text"><a href="index.html#home">Home</a></div>  </div></header>
      <div class="container body">

        <div class="content heading anchor" id="home" data-scroll-id="home" tabindex="-1" style="outline: none;">
          <div class="img"><img class="img" length="800px" height='200px' src="pic/xiao.jpeg" alt="Photo"></div>
          <div class="text info">
            <h1>Qiao Xiao</h1>
            <p>
            </p><div>Ph.D. Student</div>
            <div>Eindhoven University of Technology</div>
            <div>Email:&nbsp;q.xiao [at] tue (dot) com / qiaoxiao7282 [at] gmail (dot) com</div>
            [<span><a href="files/Qiao_Xiao_s_CV.pdf">Curriculum Vitae</a></span>]
            <p>
            <span><a href="https://scholar.google.com/citations?user=ypZ_YwoAAAAJ&hl=zh-CN">Google Scholar</a></span> /
            <span><a href="https://github.com/QiaoXiao7282">Github</a></span> /
            <span><a href="https://openreview.net/profile?id=~Qiao_Xiao1">OpenReview</a></span>
            </p><p>
          </p></div>
        
          
          <div class="text">
            <p> Qiao Xiao (肖乔) is a fourth-year Ph.D. student in <a href="https://www.tue.nl/en/research/research-groups/data-science/data-and-artificial-intelligence/data-mining">Data Mining group</a> at <a href="https://www.tue.nl/en/">Eindhoven University of Technology</a>, supervised by <a href="https://www.uni.lu/fstm-en/people/decebal-constantin-mocanu/">Prof. Decebal Constantin Mocanu </a> and <a href="https://www.tue.nl/en/research/researchers/mykola-pechenizkiy">Prof. Mykola Pechenizkiy</a>. Previously, he worked with <a href="https://yuzhanghk.github.io/">Prof. Yu Zhang</a> at <a href="https://www.sustech.edu.cn/en/">Southern University of Science and Technology</a>. His research interests include deep learning and AI efficiency, especially in sparse neural networks and data selection.
            </p>


          </div>
        </div>



        <!-- 🔥 News Section -->
        <div class="content anchor" id="news">
          <div class="text">
            <h3>🔥 News</h3>
            <ul>
              <li><strong>2025.09</strong>: Three papers accepted by TMLR.</li>
              <li><strong>2025.08</strong>: Started internship at NVIDIA 🥳</li>
              <li><strong>2025.05</strong>: Released the first KV-Cache algorithm for diffusion language models! </li>
              <li><strong>2025.05</strong>: accepted by ACL'25! See you in Vienna!</li>
            </ul>
          </div>
        </div>


        <!-- 分隔线 -->
        <hr style="border: none; border-top: 1px solid #e0e0e0; width: 60%; margin: 2em auto;" />


        <div class="content anchor" id="publications">
          <div class="text" style="z-index:1;position:relative">
            <h3 style="margin-bottom:0em">
              Publications 
                <span style="font-size: 0.9em; color:#777777;">
                  (<a id="select1" style="color:#777777; font-size: 0.9em;">* indicates equal contribution</a>)
                </span>
            </h3>
          </div>
          <!-- 🔥 News Section -->


          <div id="pubs">

          </div>


          <script id="pubs_selected" language="text">
            

        <div class="text anchor"><h4> Conference Papers </h4></div>

        <div class="publication">
              <div class="img"><img class="img" src="pic/robust.jpg" width="210" height="110" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2410.03030">Dynamic Sparse Training versus Dense Training: The Unexpected Winner in Image Corruption Robustness</a></div>
                <div class="authors">
                  <span class="author">Boqian Wu*</a></span>,
                  <span class="author jw">Qiao Xiao*</a></span>,
                  <span class="author">Shunxin Wang</a></span>,
                  <span class="author">Nicola Strisciuglio</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Maurice Van Keulen</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>,
                  <span class="author">Elena Mocanu</a></span>
                </div>
                <div>
                  International Conference on Learning Representations (<b>ICLR</b>), 2025</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2410.03030">Paper</a></span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/medical.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2312.04727">E2ENet: Dynamic Sparse Feature Fusion for Accurate and Efficient 3D Medical Image Segmentation</a></div>
                <div class="authors">
                  <span class="author">Boqian Wu*</a></span>,
                  <span class="author jw">Qiao Xiao*</a></span>,
                  <span class="author">Shiwei Liu</a></span>,
                  <span class="author">Lu Yin</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>,
                  <span class="author">Maurice Van Keulen</a></span>,
                  <span class="author">Elena Mocanu</a></span>
                </div>
                <div>
                  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2312.04727">Paper</a>/<a href="https://github.com/boqian333/E2ENet-Medical">Code</a> </span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/diff_snn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2409.09196">Are Sparse Neural Networks Better Hard Sample Learners?</a></div>
                <div class="authors">
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Boqian Wu</a></span>,
                  <span class="author">Lu Yin</a></span>,
                  <span class="author">Christopher Neil Gadzinski</a></span>,
                  <span class="author">Tianjin Huang</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>
                </div>
                <div>
                  The British Machine Vision Conference (<b>BMVC</b>), 2024</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2409.09196">Paper</a>/<a href="https://github.com/QiaoXiao7282/hard_sample_learners">Code</a> </span>]
                </div>
              </div>
      </div>

      <div class="publication">
              <div class="img"><img class="img" src="pic/asr1.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2406.18373">Dynamic Data Pruning for Automatic Speech Recognition</a></div>
                <div class="authors">
                  <span class="author jw">Qiao Xiao*</a></span>,
                  <span class="author">Pingchuan Ma*</a></span>,
                  <span class="author">Adriana Fernandez-Lopez</a></span>,
                  <span class="author">Boqian Wu</a></span>,
                  <span class="author">Lu Yin</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Maja Pantic</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>,
                  <span class="author">Shiwei Liu</a></span>
                </div>
                <div>
                  Interspeech Conference (<b>Interspeech</b>), 2024</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2406.18373">Paper</a>/<a href="https://github.com/QiaoXiao7282/DDP-ASR">Code</a> </span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/msrs.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2406.17614">MSRS: Training Multimodal Speech Recognition Models from Scratch with Sparse Mask Optimization</a></div>
                <div class="authors">
                  <span class="author">Adriana Fernandez-Lopez</a></span>,
                  <span class="author">Honglie Chen</a></span>,
                  <span class="author">Pingchuan Ma</a></span>,
                  <span class="author">Lu Yin</a></span>,
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Stavros Petridis</a></span>,
                  <span class="author">Shiwei Liu</a></span>,
                  <span class="author">Maja Pantic</a></span>
                </div>
                <div>
                  Interspeech Conference (<b>Interspeech</b>), 2024</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2406.17614">Paper</a></span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/slak.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/pdf/2207.03620">More ConvNets in the 2020s: Scaling up Kernels beyond 51x51 using Sparsity</a></div>
                <div class="authors">
                  <span class="author">Shiwei Liu</a></span>,
                  <span class="author">Tianlong Chen</a></span>,
                  <span class="author">Xiaohan Chen</a></span>,
                  <span class="author">Xuxi Chen</a></span>,
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Boqian Wu</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>,
                  <span class="author">Zhangyang Wang</a></span>
                </div>
                <div>
                  International Conference on Learning Representations (<b>ICLR</b>), 2023</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/pdf/2207.03620">Paper</a>/<a href="https://github.com/VITA-Group/SLaK">Code</a> </span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/dsn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/pdf/2212.09840">Dynamic Sparse Network for Time Series Classification: Learning What to “See”</a></div>
                <div class="authors">
                  <span class="author jw">Qiao Xiao*</a></span>,
                  <span class="author">Boqian Wu*</a></span>,
                  <span class="author">Yu Zhang</a></span>,
                  <span class="author">Shiwei Liu</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Elena Mocanu</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>

                </div>
                <div>
                  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/pdf/2212.09840">Paper</a>/<a href="https://github.com/QiaoXiao7282/DSN">Code</a> </span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/moml.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2102.07121">Multi-objective meta learning</a></div>
                <div class="authors">
                  <span class="author">Feiyang Ye*</a></span>,
                  <span class="author">Baijiong Lin*</a></span>,
                  <span class="author">Zhixiong Yue</a></span>,
                  <span class="author">Pengxin Guo</a></span>,
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Yu Zhang</a></span>

                </div>
                <div>
                  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2021</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2102.07121">Paper</a>/<a href="https://github.com/Baijiong-Lin/MOML">Code</a> </span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/aaai.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://ojs.aaai.org/index.php/AAAI/article/view/17248">Distant transfer learning via deep random walk</a></div>
                <div class="authors">
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Yu Zhang</a></span>

                </div>
                <div>
                  The Association for the Advancement of Artificial Intelligence (<b>AAAI</b>), 2021</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/17248">Paper</a></span>]
                </div>
              </div>
      </div>


        <div class="text anchor"><h4>Journal Papers </h4></div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/tip.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10766379">A Versatile Framework for Unsupervised Domain Adaptation based on Instance Weighting</a></div>
                <div class="authors">
                  <span class="author">Jinjing Zhu</a></span>,
                  <span class="author">Feiyang Ye</a></span>,
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Pengxin Guo</a></span>,
                  <span class="author">Yu Zhang</a></span>,
                  <span class="author">Qiang Yang</a></span>
                </div>
                <div>   
                  IEEE Transactions on Image Processing (<b>TIP</b>), 2024</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10766379">Paper</a> </span>]
                </div>
              </div>
      </div>

      <div class="publication">
              <div class="img"><img class="img" src="pic/tpami.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://ieeexplore.ieee.org/abstract/document/10416705">Selective Random Walk for Transfer Learning in Heterogeneous Label Spaces</a></div>
                <div class="authors">
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Yu Zhang</a></span>,
                  <span class="author">Qiang Yang</a></span>
                </div>
                <div>
                  IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2024</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://ieeexplore.ieee.org/abstract/document/10416705">Paper</a></span>]
                </div>
              </div>
      </div>


      <div class="text anchor"><h4> Preprints </h4></div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/seft.png" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2505.24037">Leave it to the Specialist: Repair Sparse LLMs with Sparse Fine-Tuning via Sparsity Evolution</a></div>
                <div class="authors">
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Alan Ansell</a></span>,
                  <span class="author">Lu Yin</a></span>,
                  <span class="author">Boqian Wu</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Shiwei Liu</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>
                </div>
                <div>
                  arXiv preprint, 2025</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2505.24037">Paper</a>/<a href="https://github.com/QiaoXiao7282/SEFT">Code</a> </span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/lips.png" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2506.00932">Addressing the Collaboration Dilemma in Low-Data Federated Learning via Transient Sparsity</a></div>
                <div class="authors">
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Boqian Wu</a></span>,
                  <span class="author">Andrey Poddubnyy</a></span>,
                  <span class="author">Elena Mocanu</a></span>,
                  <span class="author">Phuong Nguyen</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>
                </div>
                <div>
                  arXiv preprint, 2025</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2506.00932">Paper</a>/<a href="https://github.com/QiaoXiao7282/LIPS">Code</a> </span>]
                </div>
              </div>
      </div>


      <div class="publication">
              <div class="img"><img class="img" src="pic/trails.png" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
              <div class="text">
                <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2505.17909">NeuroTrails: Training with Dynamic Sparse Heads as the Key to Effective Ensembling</a></div>
                <div class="authors">
                  <span class="author">Bram Grooten</a></span>,
                  <span class="author">Farid Hasanov</a></span>,
                  <span class="author">Chenxiang Zhang</a></span>,
                  <span class="author jw">Qiao Xiao</a></span>,
                  <span class="author">Boqian Wu</a></span>,
                  <span class="author">Zahra Atashgahi</a></span>,
                  <span class="author">Ghada Sokar</a></span>,
                  <span class="author">Shiwei Liu</a></span>,
                  <span class="author">Lu Yin</a></span>,
                  <span class="author">Elena Mocanu</a></span>,
                  <span class="author">Mykola Pechenizkiy</a></span>,
                  <span class="author">Decebal Constantin Mocanu</a></span>
                </div>
                <div>
                  arXiv preprint, 2025</a></span>
                </div>
                <div>
                  [<span class="highlight"><a href="https://arxiv.org/abs/2505.17909">Paper</a>/<a href="https://github.com/bramgrooten/neurotrails">Code</a> </span>]

                </div>
              </div>
      </div>


          </script>    


          
          <script id="pubs_by_date" language="text">

      <div class="text anchor"><h4>2023 (7)</h4></div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023interspeech_streaming.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2211.02133">Streaming Audio-Visual Speech Recognition with Alignment Regularization</a></div>
                    <div class="authors">
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Niko Moritz</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Christian Fuegen</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023interspeech_sparse.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2307.04552">SparseVSR: Lightweight and Noise Robust Visual Speech Recognition</a></div>
                    <div class="authors">
                      <span class="author">Adriana Fernandez-Lopez</a></span>,
                      <span class="author">Honglie Chen</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>
                      Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2023</a></span>
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023cvpr_synthvsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.17200">SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision</a></div>
                    <div class="authors">
                      <span class="author">Xubo Liu</a></span>,
                      <span class="author">Egor Lakomkin</a></span>,
                      <span class="author">Konstantinos Vougioukas</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Honglie Chen</a></span>,
                      <span class="author">Ruiming Xie</a></span>,
                      <span class="author">Morrie Doulaty</a></span>,
                      <span class="author">Niko Moritz</a></span>,
                      <span class="author">Jáchym Kolář</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023icassp_autoavsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.14307">Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels</a></div>
                    <div class="authors">
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author">Adriana Fernandez-Lopez</a></span>,
                      <span class="author">Honglie Chen</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2023</a></span> 
                    </div>
                    <div>
                      [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                    </div>
                  </div>
          </div>


          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023icassp_multiple.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2303.09455">Learning Cross-lingual Visual Speech Representations</a></div>
                    <div class="authors">
                      <span class="author">Andreas Zinonos</a></span>,
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>


          <div class="publication"> 
                  <div class="img"><img class="img" src="pics/2023iclr_raven.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2212.06246">Jointly Learning Visual and Auditory Speech Representations from Raw Data</a></div>
                    <div class="authors">
                      <span class="author">Alexandros Haliassos</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Rodrigo Mira</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      International Conference on Learning Representations (<b>ICLR</b>), 2023</a></span> 
                    </div>
                    <div>
                      [<span class="highlight"><a href="https://github.com/ahaliassos/raven">Code/Models</a></span>]
                    </div>
                  </div>
          </div>

          <div class="publication">
                  <div class="img"><img class="img" src="pics/2023tpami_ssl.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                  <div class="text">
                    <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2203.13166">Self-supervised Video-centralised Transformer for Video Face Clustering</a></div>
                    <div class="authors">
                      <span class="author">Yujiang Wang</a></span>,
                      <span class="author">Mingzhi Dong</a></span>,
                      <span class="author">Jie Shen</a></span>,
                      <span class="author">Yiming Luo</a></span>,
                      <span class="author">Yiming Lin</a></span>,
                      <span class="author jw">Pingchuan Ma</a></span>,
                      <span class="author">Stavros Petridis</a></span>,
                      <span class="author">Maja Pantic</a></span>
                    </div>
                    <div>   
                      IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023</a></span> 
                    </div>
                  </div>
          </div>

           
            <div class="text anchor"><h4>2022 (4)</h4></div>   

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022nature_visual.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2202.13084">Visual Speech Recognition for Multiple Languages in the Wild</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Nature Machine Intelligence (<b>Nature ML</b>), 2022</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Visual_Speech_Recognition_for_Multiple_Languages">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022icassp_training.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2209.01383">Training Strategies for Improved Lip-Reading</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Yujiang Wang</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2022</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022cybernetics_v2a.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2104.13332">End-to-End Video-To-Speech Synthesis using Generative Adversarial Networks</a></div>
                          <div class="authors">
                            <span class="author">Rodrigo Mira</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Björn W. Schuller</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE Transactions on Cybernetics, 2022</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2022frontiers_animation.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://www.frontiersin.org/articles/10.3389/fnins.2021.781196">Speech-driven Facial Animations Improve Speech-in-Noise Comprehension of Humans</a></div>
                          <div class="authors">
                            <span class="author">Enrico Varano</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>,
                            <span class="author">Tobias Reichenbach</a></span>

                          </div>
                          <div>   
                            Frontiers in Neuroscience, 2022</a></span> 
                          </div>
                        </div>
                </div>



            <div class="text anchor"><h4>2021 (5)</h4></div>   

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021interspeech_lira.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2106.09171">LiRA: Learning Visual Speech Representations from Audio through Self-supervision</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Rodrigo Mira*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Björn W. Schuller</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2021</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication">
                        <div class="img"><img class="img" src="pics/2021icassp_towards.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2007.06504">Towards Practical Lipreading with Distilled and Efficient Models</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Brais Martinez*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021icassp_conformer.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2102.06657">End-to-End Audio-visual Speech Recognition with Conformers</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/auto_avsr">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021icassp_detecting.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1912.08639">Detecting Adversarial Attacks on Audio-visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2021</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2021wacv_dctcn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2009.14233">Lip-reading with Densely Connected Temporal Convolutional Networks</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Yujiang Wang*</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

            <div class="text anchor"><h4>2020 (4)</h4></div>   
                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_pose2.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1911.06095">Towards Pose-invariant Lip-Reading</a></div>
                          <div class="authors">
                            <span class="author">Shiyang Cheng*</a></span>,
                            <span class="author jw">Pingchuan Ma*</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Adrian Bulat</a></span>,
                            <span class="author">Jie Shen</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                        </div>
                </div>


                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_tcn.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2001.08702">Lipreading Using Temporal Convolutional Networks</a></div>
                          <div class="authors">
                            <span class="author">Brais Martinez</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks">Code/Models</a></span>]
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020icassp_ssl.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/2001.04316">Visually Guided Self-Supervised Learning of Speech Representations</a></div>
                          <div class="authors">
                            <span class="author">Abhinav Shukla</a></span>,
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2020</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2020prl_small.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1904.01954">End-to-End Visual Speech Recognition for Small-Scale Datasets</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Yujiang Wang</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Zuwei Li</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Pattern Recognition Letters, 2020</a></span> 
                          </div>
                        </div>
                </div>


            <div class="text anchor"><h4>2019 (2)</h4></div>
            
                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2019interspeech_lombard.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1906.02112">Investigating the Lombard Effect Influence on End-to-End Audio-Visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2019</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2019interspeech_animation.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1906.06301">Video-Driven Speech Reconstruction using Generative Adversarial Networks</a></div>
                          <div class="authors">
                            <span class="author">Konstantinos Vougioukas</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Conference of the International Speech Communication Association (<b>INTERSPEECH</b>), 2019</a></span> 
                          </div>
                        </div>
                </div>


            <div class="text anchor"><h4>2018 (2)</h4></div>

                <div class="publication">
                        <div class="img"><img class="img" src="pics/2018slt_hybrid.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1810.00108">Audio-visual Speech Recognition with a Hybrid CTC/Attention Architecture</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Themos Stafylakis</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            Spoken Language Technology Workshop (<b>SLT</b>), 2018</a></span> 
                          </div>
                        </div>
                </div>

                <div class="publication"> 
                        <div class="img"><img class="img" src="pics/2018icassp_avsr.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                        <div class="text">
                          <div class="venue"><a name="jenga_scirobot" href="https://arxiv.org/abs/1802.06424">End-to-end Audio-visual Speech Recognition</a></div>
                          <div class="authors">
                            <span class="author">Stavros Petridis</a></span>,
                            <span class="author">Themos Stafylakis</a></span>,
                            <span class="author jw">Pingchuan Ma</a></span>,
                            <span class="author">Georgios Tzimiropoulos</a></span>,
                            <span class="author">Maja Pantic</a></span>
                          </div>
                          <div>   
                            IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2018</a></span> 
                          </div>
                          <div>
                            [<span class="highlight"><a href="https://github.com/mpc001/end-to-end-lipreading">Code/Models</a></span>]
                          </div>
                        </div>
                </div>


          <div class="text anchor"><h4>2016 (1)</h4></div>

            <div class="publication"> 
                    <div class="img"><img class="img" src="pics/2016infomration_rotated.jpg" width="210" height="95" style="box-shadow: 4px 4px 8px #888" alt="spotlight_jenga"></div>
                    <div class="text">
                      <div class="venue"><a name="jenga_scirobot" href="https://link.springer.com/article/10.1007/s11432-015-5372-0">Rotated Neighbor Learning-Based Auto-Configured Evolutionary Algorithm</a></div>
                      <div class="authors">
                        <span class="author">Yuanjun Laili</a></span>,
                        <span class="author">Lin Zhang</a></span>,
                        <span class="author">Fei Tao</a></span>,
                        <span class="author jw">Pingchuan Ma</a></span>
                      </div>
                      <div>   
                        Science China Information Sciences, 2016</a></span> 
                      </div>
                    </div>
            </div>  


          </script>


        </div>  <!-- content -->

      </div> <!-- container -->
    </div> <!-- outer container -->

    <script>showPubs(0);</script>
    <script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>

  

<div id="footer">
  <div id="footer-text"></div>
</div>
  <p><center>


  </div>        
  <br>
     
  </center></p>
</div>


</body><div id="__genieContainer" style="all: initial;"></div></html>
